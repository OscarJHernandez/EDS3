{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/anaconda3/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/anaconda3/envs/py35/lib/python3.5/site-packages/pandas/io/parsers.py:2230: FutureWarning: split() requires a non-empty pattern match.\n",
      "  yield pat.split(line.strip())\n",
      "/home/javier/anaconda3/envs/py35/lib/python3.5/site-packages/pandas/io/parsers.py:2232: FutureWarning: split() requires a non-empty pattern match.\n",
      "  yield pat.split(line.strip())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   img_ID  is_person  is_dog  is_cat  is_bird  is_horse is_other\n",
      "0  005375          1      -1      -1       -1        -1       -1\n",
      "1  004932          1      -1      -1       -1        -1       -1\n",
      "2  007171         -1      -1      -1       -1        -1        1\n",
      "3  004454          1      -1      -1       -1        -1       -1\n",
      "4  002863          1      -1      -1       -1        -1       -1\n",
      "\n",
      "The total number of images:  4411\n",
      "Number of Persons:  1599\n",
      "Number of Dogs:  297\n",
      "Number of Cats:  278\n",
      "Number of Horses:  464\n",
      "Number of Birds:  263\n",
      "Number of Others:  1510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The root directory for the data files\n",
    "root_directory = 'VOCtest_06-Nov-2007/ImageSets/Main/'\n",
    "img_directory = 'VOCtest_06-Nov-2007/JPEGImages/'\n",
    "\n",
    "# The object list\n",
    "object_list = ['person','dog','cat','horse','bird','other']\n",
    "\n",
    "# The specific files containing the lists that \n",
    "person_set ='person_test.txt'\n",
    "dog_set = 'dog_test.txt'\n",
    "cat_set = 'cat_test.txt'\n",
    "horse_set = 'car_test.txt'\n",
    "bird_set = 'bird_test.txt'\n",
    "\n",
    "# Create a pandas data frame for each of the test files\n",
    "person_data = pd.read_csv(root_directory+person_set, header = None, sep=r\"\\s*\",engine='python', dtype=str)\n",
    "dog_data = pd.read_csv(root_directory+dog_set, header = None, sep=r\"\\s*\",engine='python', dtype=str)\n",
    "cat_data = pd.read_csv(root_directory+cat_set, header = None, sep=r\"\\s*\",engine='python', dtype=str)\n",
    "horse_data = pd.read_csv(root_directory+horse_set, header = None, sep=r\"\\s*\",engine='python', dtype=str)\n",
    "bird_data = pd.read_csv(root_directory+bird_set, header = None, sep=r\"\\s*\",engine='python', dtype=str)\n",
    "\n",
    "\n",
    "# Create the columns \n",
    "person_data.columns = [\"img_ID\", \"is_person\"]\n",
    "dog_data.columns = [\"img_ID\", \"is_dog\"]\n",
    "cat_data.columns = [\"img_ID\", \"is_cat\"]\n",
    "horse_data.columns = [\"img_ID\", \"is_horse\"]\n",
    "bird_data.columns = [\"img_ID\", \"is_bird\"]\n",
    "\n",
    "person_data.is_person = person_data.is_person.astype(int)\n",
    "dog_data.is_dog = dog_data.is_dog.astype(int)\n",
    "cat_data.is_cat = cat_data.is_cat.astype(int)\n",
    "horse_data.is_horse = horse_data.is_horse.astype(int)\n",
    "bird_data.is_bird = bird_data.is_bird.astype(int)\n",
    "\n",
    "\n",
    "# Now we join the data according to the ID column\n",
    "df = pd.merge(person_data, dog_data, on='img_ID')\n",
    "df = pd.merge(df, cat_data, on='img_ID')\n",
    "df = pd.merge(df, bird_data, on='img_ID')\n",
    "df = pd.merge(df, horse_data, on='img_ID')\n",
    "\n",
    "\n",
    "# Create a new row for 'other category'\n",
    "#'=========================================='\n",
    "other_data = pd.DataFrame(columns=['img_ID','is_other'])\n",
    "other_data['img_ID'] = df['img_ID']\n",
    "for i in range(0,len(df)):\n",
    "    x = int(sum(df.loc[i,:][1:]==-1) == len(object_list)-1)\n",
    "    \n",
    "    if x==0:\n",
    "        other_data['is_other'][i] = -1\n",
    "    else:\n",
    "        other_data['is_other'][i] = x\n",
    "#'=========================================='\n",
    "\n",
    "\n",
    "# Most images are in the 'other category'\n",
    "df = pd.merge(df, other_data, on='img_ID')\n",
    "\n",
    "\n",
    "# Now we will drop all columns that are not mutually exclusive\n",
    "keep_indx = []\n",
    "\n",
    "for k in range(0,len(df)):\n",
    "\n",
    "    if(df['is_person'].loc[k]==1 and df['is_dog'].loc[k]==-1 and df['is_cat'].loc[k]==-1 and df['is_bird'].loc[k]==-1 and df['is_horse'].loc[k]==-1):\n",
    "        keep_indx.append(k)\n",
    "    \n",
    "    if(df['is_person'].loc[k]==-1 and df['is_dog'].loc[k]==1 and df['is_cat'].loc[k]==-1 and df['is_bird'].loc[k]==-1 and df['is_horse'].loc[k]==-1):\n",
    "        keep_indx.append(k)\n",
    "    \n",
    "    if(df['is_person'].loc[k]==-1 and df['is_dog'].loc[k]==-1 and df['is_cat'].loc[k]==1 and df['is_bird'].loc[k]==-1 and df['is_horse'].loc[k]==-1):\n",
    "        keep_indx.append(k)\n",
    "    \n",
    "    if(df['is_person'].loc[k]==-1 and df['is_dog'].loc[k]==-1 and df['is_cat'].loc[k]==-1 and df['is_bird'].loc[k]==1 and df['is_horse'].loc[k]==-1):\n",
    "        keep_indx.append(k)\n",
    "        \n",
    "    if(df['is_person'].loc[k]==-1 and df['is_dog'].loc[k]==-1 and df['is_cat'].loc[k]==-1 and df['is_bird'].loc[k]==-1 and df['is_horse'].loc[k]==1):\n",
    "        keep_indx.append(k)\n",
    "    \n",
    "    if(df['is_person'].loc[k]==-1 and df['is_dog'].loc[k]==-1 and df['is_cat'].loc[k]==-1 and df['is_bird'].loc[k]==-1 and df['is_horse'].loc[k]==-1):\n",
    "        keep_indx.append(k)\n",
    "\n",
    "# Copy the mutually exclusive pictures, then shuffle the data and reset the index\n",
    "df = df.loc[keep_indx]\n",
    "#df = df.reset_index(drop=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Count the number of objects in each category\n",
    "total_N = len(df)\n",
    "other_N = df[df.is_other == 1].is_other.sum()\n",
    "person_N = df[df.is_person == 1].is_person.sum()\n",
    "dog_N = df[df.is_dog == 1].is_dog.sum()\n",
    "cat_N = df[df.is_cat == 1].is_cat.sum()\n",
    "horse_N = df[df.is_horse == 1].is_horse.sum()\n",
    "bird_N = df[df.is_bird == 1].is_bird.sum()\n",
    "\n",
    "print('')\n",
    "print('The total number of images: ', total_N)\n",
    "print('Number of Persons: ',person_N)  \n",
    "print('Number of Dogs: ',dog_N)  \n",
    "print('Number of Cats: ',cat_N)  \n",
    "print('Number of Horses: ',horse_N)  \n",
    "print('Number of Birds: ',bird_N)  \n",
    "print('Number of Others: ',other_N)  \n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "dropped:  0\n",
      "new other number:  56\n",
      "new person number:  56\n",
      "new dog number:  56\n",
      "new cat number:  56\n",
      "new horse number:  56\n",
      "new bird number:  56\n",
      "New Dataframe 336\n",
      "   img_ID  is_person  is_dog  is_cat  is_bird  is_horse is_other\n",
      "0  008089         -1      -1       1       -1        -1       -1\n",
      "1  009317          1      -1      -1       -1        -1       -1\n",
      "2  004021         -1       1      -1       -1        -1       -1\n",
      "3  000741         -1      -1       1       -1        -1       -1\n",
      "4  001133          1      -1      -1       -1        -1       -1\n",
      "=========================================\n",
      "Training set size:  269\n",
      "Validation set size:  67\n",
      "mkdir: cannot create directory ‘test’: File exists\n",
      "mkdir: cannot create directory ‘validation’: File exists\n",
      "mkdir: cannot create directory ‘test/person’: File exists\n",
      "mkdir: cannot create directory ‘validation/person’: File exists\n",
      "mkdir: cannot create directory ‘test/dog’: File exists\n",
      "mkdir: cannot create directory ‘validation/dog’: File exists\n",
      "mkdir: cannot create directory ‘test/cat’: File exists\n",
      "mkdir: cannot create directory ‘validation/cat’: File exists\n",
      "mkdir: cannot create directory ‘test/horse’: File exists\n",
      "mkdir: cannot create directory ‘validation/horse’: File exists\n",
      "mkdir: cannot create directory ‘test/bird’: File exists\n",
      "mkdir: cannot create directory ‘validation/bird’: File exists\n",
      "mkdir: cannot create directory ‘test/other’: File exists\n",
      "mkdir: cannot create directory ‘validation/other’: File exists\n",
      "mkdir: cannot create directory ‘test/person’: File exists\n",
      "mkdir: cannot create directory ‘validation/person’: File exists\n",
      "mkdir: cannot create directory ‘test/dog’: File exists\n",
      "mkdir: cannot create directory ‘validation/dog’: File exists\n",
      "mkdir: cannot create directory ‘test/cat’: File exists\n",
      "mkdir: cannot create directory ‘validation/cat’: File exists\n",
      "mkdir: cannot create directory ‘test/horse’: File exists\n",
      "mkdir: cannot create directory ‘validation/horse’: File exists\n",
      "mkdir: cannot create directory ‘test/bird’: File exists\n",
      "mkdir: cannot create directory ‘validation/bird’: File exists\n",
      "mkdir: cannot create directory ‘test/other’: File exists\n",
      "mkdir: cannot create directory ‘validation/other’: File exists\n",
      "mkdir: cannot create directory ‘test/person’: File exists\n",
      "mkdir: cannot create directory ‘validation/person’: File exists\n",
      "mkdir: cannot create directory ‘test/dog’: File exists\n",
      "mkdir: cannot create directory ‘validation/dog’: File exists\n",
      "mkdir: cannot create directory ‘test/cat’: File exists\n",
      "mkdir: cannot create directory ‘validation/cat’: File exists\n",
      "mkdir: cannot create directory ‘test/horse’: File exists\n",
      "mkdir: cannot create directory ‘validation/horse’: File exists\n",
      "mkdir: cannot create directory ‘test/bird’: File exists\n",
      "mkdir: cannot create directory ‘validation/bird’: File exists\n",
      "mkdir: cannot create directory ‘test/other’: File exists\n",
      "mkdir: cannot create directory ‘validation/other’: File exists\n",
      "mkdir: cannot create directory ‘test/person’: File exists\n",
      "mkdir: cannot create directory ‘validation/person’: File exists\n",
      "mkdir: cannot create directory ‘test/dog’: File exists\n",
      "mkdir: cannot create directory ‘validation/dog’: File exists\n",
      "mkdir: cannot create directory ‘test/cat’: File exists\n",
      "mkdir: cannot create directory ‘validation/cat’: File exists\n",
      "mkdir: cannot create directory ‘test/horse’: File exists\n",
      "mkdir: cannot create directory ‘validation/horse’: File exists\n",
      "mkdir: cannot create directory ‘test/bird’: File exists\n",
      "mkdir: cannot create directory ‘validation/bird’: File exists\n",
      "mkdir: cannot create directory ‘test/other’: File exists\n",
      "mkdir: cannot create directory ‘validation/other’: File exists\n",
      "mkdir: cannot create directory ‘test/person’: File exists\n",
      "mkdir: cannot create directory ‘validation/person’: File exists\n",
      "mkdir: cannot create directory ‘test/dog’: File exists\n",
      "mkdir: cannot create directory ‘validation/dog’: File exists\n",
      "mkdir: cannot create directory ‘test/cat’: File exists\n",
      "mkdir: cannot create directory ‘validation/cat’: File exists\n",
      "mkdir: cannot create directory ‘test/horse’: File exists\n",
      "mkdir: cannot create directory ‘validation/horse’: File exists\n",
      "mkdir: cannot create directory ‘test/bird’: File exists\n",
      "mkdir: cannot create directory ‘validation/bird’: File exists\n",
      "mkdir: cannot create directory ‘test/other’: File exists\n",
      "mkdir: cannot create directory ‘validation/other’: File exists\n",
      "mkdir: cannot create directory ‘test/person’: File exists\n",
      "mkdir: cannot create directory ‘validation/person’: File exists\n",
      "mkdir: cannot create directory ‘test/dog’: File exists\n",
      "mkdir: cannot create directory ‘validation/dog’: File exists\n",
      "mkdir: cannot create directory ‘test/cat’: File exists\n",
      "mkdir: cannot create directory ‘validation/cat’: File exists\n",
      "mkdir: cannot create directory ‘test/horse’: File exists\n",
      "mkdir: cannot create directory ‘validation/horse’: File exists\n",
      "mkdir: cannot create directory ‘test/bird’: File exists\n",
      "mkdir: cannot create directory ‘validation/bird’: File exists\n",
      "mkdir: cannot create directory ‘test/other’: File exists\n",
      "mkdir: cannot create directory ‘validation/other’: File exists\n"
     ]
    }
   ],
   "source": [
    "# Find the catefory with the minimum objects\n",
    "min_object_N = min(total_N,person_N, dog_N,cat_N,horse_N,bird_N,other_N)\n",
    "\n",
    "# Given all the data, we now split the set into a training and validation set.\n",
    "# 1. Randomly shuffle all of the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 1.5 Remove a large number of objects in the categories\n",
    "dropped_others=0\n",
    "dropped_persons =0\n",
    "dropped_dogs =0\n",
    "dropped_cats = 0\n",
    "dropped_birds= 0\n",
    "dropped_horses=0\n",
    "\n",
    "drop_indx = []\n",
    "for k in range(0,len(df)):\n",
    "\n",
    "    if(df['is_other'].loc[k]==1 and dropped_others < (other_N-min_object_N) and k not in drop_indx ):\n",
    "        drop_indx.append(k)\n",
    "        dropped_others+=1\n",
    "    \n",
    "    if(df['is_person'].loc[k]==1 and dropped_persons < (person_N-min_object_N) and k not in drop_indx ):\n",
    "        drop_indx.append(k)\n",
    "        dropped_persons+=1\n",
    "        \n",
    "        \n",
    "    if(df['is_cat'].loc[k]==1 and dropped_cats< (cat_N-min_object_N) and k not in drop_indx ):\n",
    "        drop_indx.append(k)\n",
    "        dropped_cats+=1\n",
    "        \n",
    "    if(df['is_dog'].loc[k]==1 and dropped_dogs < (dog_N-min_object_N) and k not in drop_indx ):\n",
    "        drop_indx.append(k)\n",
    "        dropped_dogs+=1\n",
    "        \n",
    "    if(df['is_horse'].loc[k]==1 and dropped_horses < (horse_N-min_object_N) and k not in drop_indx ):\n",
    "        drop_indx.append(k)\n",
    "        dropped_horses+=1\n",
    "    \n",
    "    if(df['is_bird'].loc[k]==1 and dropped_birds < (bird_N-min_object_N) and k not in drop_indx ):\n",
    "        drop_indx.append(k)\n",
    "        dropped_birds+=1\n",
    "\n",
    "# Drop the desired data and shuffle the indices \n",
    "df.drop(df.index[drop_indx], inplace=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "#df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "other_N = df[df.is_other == 1].is_other.sum()\n",
    "person_N = df[df.is_person == 1].is_person.sum()\n",
    "dog_N = df[df.is_dog == 1].is_dog.sum()\n",
    "cat_N = df[df.is_cat == 1].is_cat.sum()\n",
    "horse_N = df[df.is_horse == 1].is_horse.sum()\n",
    "bird_N = df[df.is_bird == 1].is_bird.sum()\n",
    "\n",
    "print('=========================================')\n",
    "print('dropped: ', len(drop_indx))\n",
    "print('new other number: ', other_N)\n",
    "print('new person number: ', person_N)\n",
    "print('new dog number: ', dog_N)\n",
    "print('new cat number: ', cat_N)\n",
    "print('new horse number: ', horse_N)\n",
    "print('new bird number: ', bird_N)\n",
    "print('New Dataframe',len(df))\n",
    "print(df.head())\n",
    "print('=========================================')\n",
    "\n",
    "\n",
    "# 2. Create a test and validation data frame\n",
    "#    The first N*f are the training set, afterwards, validations\n",
    "msk = []\n",
    "test_validation_split = 0.8\n",
    "N_train = int(test_validation_split*len(df))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    if(i<=N_train):\n",
    "        msk.append(True)\n",
    "    else:\n",
    "        msk.append(False)\n",
    "        \n",
    "# Convert to the Numpy array \n",
    "msk =np.asarray(msk)\n",
    " \n",
    "\n",
    "# Split the data_frames into test and train\n",
    "df_train = df[msk]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "df_validation = df[~msk]\n",
    "df_validation = df_validation.reset_index(drop=True)\n",
    "\n",
    "print('Training set size: ', len(df_train))\n",
    "print('Validation set size: ', len(df_validation))\n",
    "\n",
    "#==========================================================================================\n",
    "# 3. Generate subfolders with the class names for the test and validation sets\n",
    "f = open(\"create_subfolders.sh\", \"a\")\n",
    "commands ='''\n",
    "#!/bin/sh\n",
    "'''\n",
    "commands+= 'for object in '\n",
    "\n",
    "for object in object_list:\n",
    "    commands+= object+' '\n",
    "commands+='''\n",
    "do\n",
    "    mkdir 'test/'$object\n",
    "    mkdir 'validation/'$object\n",
    "done\n",
    "'''\n",
    "f.write(commands)\n",
    "f.close()\n",
    "\n",
    "# Run the newly generated bash file\n",
    "! mkdir test\n",
    "! mkdir validation\n",
    "! bash create_subfolders.sh\n",
    "#==========================================================================================\n",
    "\n",
    "# 4. Iterate over the training and validation data frames:\n",
    "# * For each 1, add the image to the corresponding subfolder\n",
    "for k in range(0,len(df_train)):\n",
    "    \n",
    "    img_name = df_train.iloc[k,:][0]\n",
    "    \n",
    "    is_dog = (df_train['is_dog'].iloc[k] == 1)\n",
    "    is_cat = (df_train['is_cat'].iloc[k] == 1)\n",
    "    is_horse = (df_train['is_horse'].iloc[k] == 1)\n",
    "    is_other = (df_train['is_other'].iloc[k] == 1)\n",
    "    is_bird = (df_train['is_bird'].iloc[k] == 1)\n",
    "    is_person = (df_train['is_person'].iloc[k] == 1)\n",
    "    \n",
    "    if(is_dog== True):\n",
    "        folder = 'dog/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','test/'+folder+img_name+'.jpg')\n",
    "        \n",
    "    if(is_person== True):\n",
    "        folder = 'person/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','test/'+folder+img_name+'.jpg')\n",
    "    \n",
    "    if(is_cat== True):\n",
    "        folder = 'cat/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','test/'+folder+img_name+'.jpg')\n",
    "        \n",
    "    if(is_horse== True):\n",
    "        folder = 'horse/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','test/'+folder+img_name+'.jpg')\n",
    "    \n",
    "    if(is_bird== True):\n",
    "        folder = 'bird/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','test/'+folder+img_name+'.jpg')\n",
    "    \n",
    "    if(is_other== True):\n",
    "        folder = 'other/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','test/'+folder+img_name+'.jpg')\n",
    "\n",
    "for k in range(0,len(df_validation)):\n",
    "    \n",
    "    img_name = df_validation.iloc[k,:][0]\n",
    "    \n",
    "    is_dog = (df_validation['is_dog'].iloc[k] == 1)\n",
    "    is_cat = (df_validation['is_cat'].iloc[k] == 1)\n",
    "    is_horse = (df_validation['is_horse'].iloc[k] == 1)\n",
    "    is_other = (df_validation['is_other'].iloc[k] == 1)\n",
    "    is_bird = (df_validation['is_bird'].iloc[k] == 1)\n",
    "    is_person = (df_validation['is_person'].iloc[k] == 1)\n",
    "    \n",
    "    if(is_dog== True):\n",
    "        folder = 'dog/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','validation/'+folder+img_name+'.jpg')\n",
    "    \n",
    "    if(is_person== True):\n",
    "        folder = 'person/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','validation/'+folder+img_name+'.jpg')\n",
    "    \n",
    "    if(is_cat== True):\n",
    "        folder = 'cat/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','validation/'+folder+img_name+'.jpg')\n",
    "        \n",
    "    if(is_horse== True):\n",
    "        folder = 'horse/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','validation/'+folder+img_name+'.jpg')\n",
    "    \n",
    "    if(is_bird== True):\n",
    "        folder = 'bird/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','validation/'+folder+img_name+'.jpg')\n",
    "    \n",
    "    if(is_other== True):\n",
    "        folder = 'other/'\n",
    "        shutil.copyfile(img_directory+img_name+'.jpg','validation/'+folder+img_name+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let us load in the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "\n",
    "# This will augment the training images to make the detector more robust \n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(img_directory+'000015'+'.jpg')  # this is a PIL image\n",
    "img = img.resize((250, 250))\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (375, 500,3)\n",
    "print(x.shape)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 375, 500, 3)\n",
    "print(x.shape)\n",
    "\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='img', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we build the model that will classify the images\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# dimensions of our images vary in size\n",
    "img_width, img_height = 250,250 \n",
    "\n",
    "# Here we specify the directory for our training and validation images\n",
    "train_data_dir = 'test'\n",
    "validation_data_dir = 'validation'\n",
    "\n",
    "# The number of training and validation samples\n",
    "nb_train_samples = len(df_train)\n",
    "nb_validation_samples = len(df_validation)\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(object_list)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the final model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              #optimizer='rmsprop',\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 269\n",
      "Validation samples:  67\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 248, 248, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 248, 248, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 122, 122, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 122, 122, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 59, 59, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                3444800   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 3,473,830\n",
      "Trainable params: 3,473,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Train samples:',nb_train_samples)\n",
    "print('Validation samples: ', nb_validation_samples)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = 'weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "tensorboard = TensorBoard(log_dir = './logs', histogram_freq=0,batch_size=batch_size, write_graph=True)#, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we fit the model, takes some time.\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size,\n",
    "    callbacks=[checkpointer])\n",
    "\n",
    "# Here I save the weights of the trained model\n",
    "model.save_weights('model1.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [0] [[1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "img_width,img_height = 250,250\n",
    "test_model = model.load_weights('model1.h5')\n",
    "img = load_img('validation/bird/000569.jpg',False,target_size=(img_width,img_height))\n",
    "\n",
    "plt.show(img)\n",
    "\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "preds = model.predict_classes(x)\n",
    "prob = model.predict_proba(x)\n",
    "classes = model.predict(x).argmax(axis=-1)\n",
    "\n",
    "#y_prob = model.predict(x) \n",
    "#y_classes = y_prob.argmax(axis=-1)\n",
    "\n",
    "print(classes,preds, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
